{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq:\n",
    "    \n",
    "    def __init__(self, name, description, sequence):\n",
    "        self.name = name.lstrip('>')\n",
    "        self.desc = description.split('(')[1].split(')')[0]\n",
    "        self.seq = sequence.lower()\n",
    "\n",
    "\n",
    "def read_seq(file):\n",
    "    with open(file, 'r') as f:\n",
    "        con = [i.rstrip('\\n') for i in f.readlines()]\n",
    "    return Seq(con[0], con[1], ''.join(con[2:]))\n",
    "\n",
    "\n",
    "def load_sequences(folder):\n",
    "    seq_files = [os.path.join(folder, i) for i in os.listdir(folder) if not i.startswith('.')]\n",
    "    seqs = list(map(read_seq, seq_files))\n",
    "    seqs_df_rows = [(x.name, x.desc, x.seq) for x in tqdm(seqs)]\n",
    "    seqs_df = pd.DataFrame(seqs_df_rows, columns=['Name','CDSjoin','Sequence'])\n",
    "    return seqs_df\n",
    "\n",
    "def load_data():\n",
    "    training_set = pd.read_hdf('../Data_files/features&labels/testing_set.h5')\n",
    "    testing_set = pd.read_hdf('../Data_files/features&labels/testing_set.h5')\n",
    "    return (training_set, testing_set)\n",
    "\n",
    "def Summary(tr1, ts1, tr2, ts2):\n",
    "    Sum = pd.DataFrame()\n",
    "    Sum['nDonor (Training)'] = [tr1['IsDonor'].value_counts()[1], tr2['IsDonor'].value_counts()[1]]\n",
    "    Sum['nPseudo (Training)'] = [tr1['IsDonor'].value_counts()[0], tr2['IsDonor'].value_counts()[0]]\n",
    "    Sum['nDonor (Testing)'] = [ts1['IsDonor'].value_counts()[1], ts2['IsDonor'].value_counts()[1]]\n",
    "    Sum['nPseudo (Testing)'] = [ts1['IsDonor'].value_counts()[0], ts2['IsDonor'].value_counts()[0]]\n",
    "    Sum['nSample'] = [ts1.shape[0]+tr1.shape[0], ts2.shape[0]+tr2.shape[0]]\n",
    "    Sum['nDonor : nPSeudo'] = Sum['nDonor (Training)'].apply(str) + ' : ' + Sum['nPseudo (Training)'].apply(str)\n",
    "    Sum['Type'] = ['Unbalanced', 'Balanced']\n",
    "    Sum.index = ['Dataset 1', 'Dataset 2']\n",
    "    return Sum"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training_set, testing_set = load_data()\n",
    "training_set1 = training_set[0:5000]\n",
    "testing_set1 = testing_set[0:5000]\n",
    "training_set2 = training_set[1500:6500].reset_index(drop=True)\n",
    "testing_set2 = testing_set[1500:6500].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
