{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq:\n",
    "    \n",
    "    def __init__(self, name, description, sequence):\n",
    "        self.name = name.lstrip('>')\n",
    "        self.desc = description.split('(')[1].split(')')[0]\n",
    "        self.seq = sequence.lower()\n",
    "\n",
    "\n",
    "def read_seq(file):\n",
    "    with open(file, 'r') as f:\n",
    "        con = [i.rstrip('\\n') for i in f.readlines()]\n",
    "    return Seq(con[0], con[1], ''.join(con[2:]))\n",
    "\n",
    "\n",
    "def load_sequences(folder):\n",
    "    seq_files = [os.path.join(folder, i) for i in os.listdir(folder) if not i.startswith('.')]\n",
    "    seqs = map(read_seq, seq_files)\n",
    "    seqs_df_rows = [(x.name, x.desc, x.seq) for x in tqdm(seqs)]\n",
    "    seqs_df = pd.DataFrame(seqs_df_rows, columns=['Name','CDSjoin','Sequence'])\n",
    "    return seqs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WAM模型\n",
    "### 属性\n",
    "- chunksize\n",
    "    - 样本窗口宽度\n",
    "- arr_length\n",
    "    - 考虑碱基关联的阶数\n",
    "- positive_weights\n",
    "    - 阳性样本权重\n",
    "- negative_weights\n",
    "    - 阴性样本权重\n",
    "### 方法\n",
    "- fit\n",
    "    - 拆分阳性和阴性样本\n",
    "    - 统计碱基信息\n",
    "    - 更新权重及归一化\n",
    "- predict\n",
    "    - predict_probas计算概率\n",
    "    - predict_scores打分\n",
    "    - predict_classes分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WAM:\n",
    "    \n",
    "    def __init__(self, chunk_size=21, arr_length=2, psuedo_count=0.5):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.arr_length = arr_length\n",
    "        \n",
    "        # init wam weights\n",
    "        weights_init = np.zeros( (chunk_size, 4**arr_length) , dtype=np.float)\n",
    "        self.nucleo_arrays = self._nucleo_arrays(arr_length)\n",
    "        self.positive_weights = pd.DataFrame(weights_init, columns=self.nucleo_arrays)\n",
    "        self.negative_weights = pd.DataFrame(weights_init, columns=self.nucleo_arrays)\n",
    "        \n",
    "        # use psuedo count\n",
    "        counts_init = np.full(weights_init.shape, psuedo_count)\n",
    "        counts_init[0:2] = np.NaN\n",
    "        self._init_count_matrix = pd.DataFrame(counts_init, columns=self.nucleo_arrays)\n",
    "        \n",
    "    def fit(self, data, labels):\n",
    "        pos_indeces = labels == 1\n",
    "        neg_indeces = labels == 0\n",
    "        pos_data = data[pos_indeces].copy().reset_index(drop=True)\n",
    "        neg_data = data[neg_indeces].copy().reset_index(drop=True)\n",
    "        \n",
    "        if pos_data.shape[0] > 0: \n",
    "            self.positive_weights += self._cal_freq_matrix(pos_data)\n",
    "        if neg_data.shape[0] > 0:\n",
    "            self.negative_weights += self._cal_freq_matrix(neg_data)\n",
    "        \n",
    "        self.positive_weights = self.positive_weights.apply(lambda x: x / x.sum(), axis=0)\n",
    "        self.negative_weights = self.negative_weights.apply(lambda x: x / x.sum(), axis=0)\n",
    "        \n",
    "    def _cal_freq_matrix(self, data):\n",
    "        # init\n",
    "        count_matrix = self._init_count_matrix.copy()\n",
    "        \n",
    "        # count\n",
    "        cn = self._count_nucleo\n",
    "        count_matrix = count_matrix.apply(lambda x: x + (cn(data, x.name)), axis=0) # by column\n",
    "        #print(count_matrix)\n",
    "        # normalize\n",
    "        count_matrix = count_matrix.apply(lambda x: x / x.sum(), axis=0) # by column\n",
    "        \n",
    "        return count_matrix\n",
    "        \n",
    "    def _count_nucleo(self, data, nucleo_pattern):\n",
    "        \n",
    "        # get all ends of pattern appeared in the sequence data\n",
    "        #print(nucleo_pattern)\n",
    "        nucleo_pat = re.compile(pattern=nucleo_pattern)\n",
    "        find_ends = lambda x: [i.span()[1] for i in nucleo_pat.finditer(x)]\n",
    "        ends = data.apply(find_ends)\n",
    "\n",
    "        ends = reduce(lambda x, y: x + y, ends)\n",
    "        #print(ends)\n",
    "        # count ends as a feature vector\n",
    "        l = len(data[0])\n",
    "        \n",
    "        #counts = [ends.count(i) for i in range(self.arr_length, l)]\n",
    "        counts = [ends.count(i) for i in range(l)]\n",
    "        #print(counts)\n",
    "        return pd.Series(counts)\n",
    "        \n",
    "    def _nucleo_arrays(self, arr_length):\n",
    "        bases = ['A', 'C', 'G', 'T']\n",
    "        arrays = reduce(lambda x,y: [i+j for i in x for j in y], [bases] * arr_length)\n",
    "        return arrays\n",
    "        \n",
    "    def predict_classes(self, data, T):\n",
    "        scores = self.predict_scores(data)\n",
    "        classes = np.zeros(scores.shape, dtype=np.int)\n",
    "        isGreater = scores >= T\n",
    "        classes[isGreater] = 1\n",
    "        return classes\n",
    "        \n",
    "    def predict_probas(self, data):\n",
    "        scores = data.apply(self._score).tolist()\n",
    "        probas = pd.DataFrame(scores, columns=['Positive probability','Negative probability'])\n",
    "        return probas\n",
    "    \n",
    "    def predict_scores(self, data):\n",
    "        probas = self.predict_probas(data)\n",
    "        score = np.log( probas.apply(lambda x: x[0] / x[1], axis=1) )\n",
    "        return score\n",
    "    \n",
    "    def _score(self, sample):\n",
    "        pos_weights = self.positive_weights\n",
    "        neg_weights = self.negative_weights\n",
    "        \n",
    "        arrlen = self.arr_length\n",
    "        pos_probas = [pos_weights.loc[i, sample[i-arrlen:i]] for i in range(arrlen, len(sample))]\n",
    "        neg_probas = [neg_weights.loc[i, sample[i-arrlen:i]] for i in range(arrlen, len(sample))]\n",
    "        \n",
    "        pos_Proba = reduce(lambda x, y: x * y, pos_probas)\n",
    "        neg_Proba = reduce(lambda x, y: x * y, neg_probas)\n",
    "        \n",
    "        # return positive and negative probas\n",
    "        return [pos_Proba, neg_Proba]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BN learning: https://github.com/pgmpy/pgmpy_notebook/blob/master/notebooks/9.%20Learning%20Bayesian%20Networks%20from%20Data.ipynb\n",
    "from pgmpy.estimators import MmhcEstimator, MaximumLikelihoodEstimator, K2Score, BayesianEstimator, BDeuScore, BicScore\n",
    "from pgmpy.models import BayesianModel\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "\n",
    "class BN:\n",
    "    def __init__(self, struc_estr=MmhcEstimator, param_estr=BayesianEstimator):\n",
    "        self.struc_estr = struc_estr\n",
    "        self.param_estr = param_estr\n",
    "        \n",
    "        self.network = BayesianModel()\n",
    "        \n",
    "    def fit(self, data, label, sign_level=0.01):\n",
    "        features = pd.DataFrame(data, columns=['F{}'.format(i) for i in range(data.shape[1])])\n",
    "        label = pd.DataFrame(label, columns=['label'])\n",
    "        data = pd.concat( (features, label), axis=1)\n",
    "        \n",
    "        # structure learning\n",
    "        print('Performing structure learning, using estimator: `{}`'.format(self.struc_estr))\n",
    "        self.struc_estr = self.struc_estr(data)\n",
    "        \n",
    "        DAG = self.struc_estr.estimate(significance_level=sign_level, scoring_method=BDeuScore(data))   \n",
    "        # parameters, status for each feature ?\n",
    "        \n",
    "        self.network.add_edges_from(DAG.edges) \n",
    "        self.network.add_nodes_from( [ node for node in data.columns if not self.network.has_node(['node']) ] )\n",
    "        # plot structure\n",
    "        print('Done !')\n",
    "        print('The structure now is: ')\n",
    "        nx.draw(self.network, with_labels=True, node_color = 'b',edge_color = 'r', font_color='white', node_size=1000)\n",
    "        # parameter learning\n",
    "        print('Performing parameter learning, using estimator: `{}`'.format(self.param_estr))\n",
    "        self.network.fit(data, estimator=self.param_estr)\n",
    "        \n",
    "    \n",
    "    def predict_probas(self, data):\n",
    "        data = self.make_missingL_data(data)\n",
    "        probas = self.network.predict_probability(data)\n",
    "        return probas\n",
    "        \n",
    "    def predict_classes(self, data):\n",
    "        data = self.make_missingL_data(data)\n",
    "        classes = self.network.predict(data)\n",
    "        return classes\n",
    "        \n",
    "    def make_missingL_data(self, data):\n",
    "        features = pd.DataFrame(data, columns=['F{}'.format(i) for i in range(data.shape[1])])\n",
    "        label = pd.DataFrame(np.zeros(features.shape[0]), columns=['label'])\n",
    "        data = pd.concat( (features, label), axis=1)\n",
    "        data.drop('label', axis=1, inplace=True)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [1] Koller & Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009\n",
    "    Section 18.2.2.3 (page 789)\n",
    "    [2] Neapolitan, Learning Bayesian Networks, Section 10.3 (page 600ff)\n",
    "        http://www.cs.technion.ac.il/~dang/books/Learning%20Bayesian%20Networks(Neapolitan,%20Richard).pdf\n",
    "    [3] Chi-square test https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test#Test_of_independence\n",
    "    [4] Tsamardinos et al., The max-min hill-climbing BN structure learning algorithm, 2005, Section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tsamardinos et al., The max-min hill-climbing Bayesian network structure learning algorithm (2005),\n",
    "\n",
    "Algorithm 3\n",
    "\n",
    "http (//www.dsl-lab.org/supplements/mmhc_paper/paper_online.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "class SVM(svm.SVC):\n",
    "    \n",
    "    def predict_classes(self, data):\n",
    "        return self.predict(data)\n",
    "    \n",
    "    def predict_probas(self, data):\n",
    "        return self.predict_proba(data)\n",
    "        \n",
    "    def predict_scores(self, data):\n",
    "        probas = self.predict_probas(data)\n",
    "        scores = np.apply_along_axis(func1d=lambda x: np.log(x[0] / x[1]), arr=probas, axis=1)\n",
    "        return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
